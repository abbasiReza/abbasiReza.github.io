---
---


@article{abbasideciphering,
  abbr = {ECCV 2024},
  title={Deciphering the Role of Representation Disentanglement: Investigating Compositional Generalization in CLIP Models},
  keyword = {conference},
  author={Abbasi, Reza and Rohban, Mohammad Hossein and Baghshah, Mahdieh Soleymani}
}

@incollection{abdollahi2024gabinsight,
  abbr = {ECAI 2024},
  title={GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models},
  author={Abdollahi, Ali and Ghaznavi, Mahdi and Karimi Nejad, Mohammad Reza and Mari Oriyad, Arash and Abbasi, Reza and Salesi, Ali and Behjati, Melika and Rohban, Mohammad Hossein and Soleymani Baghshah, Mahdieh},
  booktitle={ECAI 2024},
  pages={729--736},
  year={2024},
  keyword = {conference},
  publisher={IOS Press}
}

@inproceedings{yu2024latentconceptbasedexplanationnlp,
      abbr = {EMNLP 2024},
      bibtex_show={true},
      title={Latent Concept-based Explanation of NLP Models}, 
      author={Xuemin Yu and Fahim Dalvi and Nadir Durrani and Marzia Nouri and Hassan Sajjad},
      booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)},
      year={2024},
      url={https://arxiv.org/abs/2404.12545},
      archivePrefix={arXiv},
      eprint={2404.12545},
      primaryClass={cs.CL},
      arxiv={2404.12545},
      pdf = {2404.12545v2.pdf},
      keyword = {conference},
      abstract = {Interpreting and understanding the predictions made by deep learning models poses a formidable challenge due to their inherently opaque nature. Many previous efforts aimed at explaining these predictions rely on input features, specifically, the words within NLP models. However, such explanations are often less informative due to the discrete nature of these words and their lack of contextual verbosity. To address this limitation, we introduce the Latent Concept Attribution method (LACOAT), which generates explanations for predictions based on latent concepts. Our foundational intuition is that a word can exhibit multiple facets, contingent upon the context in which it is used. Therefore, given a word in context, the latent space derived from our training process reflects a specific facet of that word. LACOAT functions by mapping the representations of salient input words into the training latent space, allowing it to provide latent context-based explanations of the prediction.}
}

@article{marioriyad2024attention,
  title={Attention Overlap Is Responsible for The Entity Missing Problem in Text-to-image Diffusion Models!},
  author={Marioriyad, Arash and Banayeeanzade, Mohammadali and Abbasi, Reza and Rohban, Mohammad Hossein and Baghshah, Mahdieh Soleymani},
  journal={arXiv preprint arXiv:2410.20972},
  keyword = {journal},
  year={2024}
}

@article{mohammad2024artificial,
  title={Artificial intelligence for detection of external cervical resorption using label-efficient self-supervised learning method},
  author={Mohammad-Rahimi, Hossein and Dianat, Omid and Abbasi, Reza and Zahedrozegar, Samira and Ashkan, Ali and Motamedian, Saeed Reza and Rohban, Mohammad Hossein and Nosrat, Ali},
  journal={Journal of Endodontics},
  volume={50},
  number={2},
  pages={144--153},
  year={2024},
  keyword = {journal},
  publisher={Elsevier}
}

